# QUICK START: Hierarchical Block Diffusion

## ğŸ¯ Má»¥c tiÃªu
ThÃªm hierarchical reasoning (Plan-then-Generate) vÃ o BD3-LM Ä‘á»ƒ model cÃ³ thá»ƒ:
1. Äá»c Question
2. Táº¡o Plan (high-level reasoning)
3. Thá»±c thi Execution (detailed steps)

vá»›i constraint: **Plan KHÃ”NG thá»ƒ nhÃ¬n tháº¥y Execution** (causal)

## ğŸ“¦ Files Ä‘Ã£ táº¡o

| File | Má»¥c Ä‘Ã­ch |
|------|---------|
| `models/hierarchical_mask.py` | Attention mask phÃ¢n táº§ng |
| `hierarchical_dataloader.py` | Data collator cho [Q, P, E] format |
| `configs/algo/hierarchical.yaml` | Config hierarchical training |
| `scripts/train/train_hierarchical_bd3lm.sh` | Training script |
| `test_hierarchical_mask.py` | Test mask correctness |
| `HIERARCHICAL_README.md` | Full docs (Vietnamese) |
| `IMPLEMENTATION_SUMMARY.md` | Detailed summary |

## âš¡ Cháº¡y thá»­ ngay (3 bÆ°á»›c)

### BÆ°á»›c 1: Test mask
```bash
cd /workspace/hdp-diffusion
python test_hierarchical_mask.py
```
Káº¿t quáº£ mong Ä‘á»£i:
- âœ… All tests passed
- ğŸ“Š File `hierarchical_mask_test.png` Ä‘Æ°á»£c táº¡o

### BÆ°á»›c 2: Chuáº©n bá»‹ data máº«u
```python
# Táº¡o file test_data.json
[
  {
    "question": "What is machine learning?",
    "plan": "I will first define ML, then explain key concepts.",
    "execution": "Machine learning is a field of AI that enables computers to learn from data without being explicitly programmed. Key concepts include: 1) Training data..."
  }
]
```

### BÆ°á»›c 3: Train thá»­ (vá»›i data nhá»)
```bash
# Edit script Ä‘á»ƒ giáº£m sá»‘ steps (test nhanh)
vim scripts/train/train_hierarchical_bd3lm.sh
# Set: MAX_STEPS=1000

# Run
sbatch scripts/train/train_hierarchical_bd3lm.sh
```

## ğŸ”§ TÃ¹y chá»‰nh nhanh

### Thay Ä‘á»•i Ä‘á»™ dÃ i blocks
```bash
# Trong training script:
QUESTION_LEN=128  # Giáº£m tá»« 256
PLAN_LEN=384      # TÄƒng tá»« 256  
EXEC_LEN=512      # Giá»¯ nguyÃªn
```

### Thay Ä‘á»•i block size (speed vs quality)
```bash
BLOCK_SIZE=8   # Nhanh hÆ¡n, cháº¥t lÆ°á»£ng tháº¥p hÆ¡n
BLOCK_SIZE=16  # CÃ¢n báº±ng (recommended)
BLOCK_SIZE=32  # Cháº­m hÆ¡n, cháº¥t lÆ°á»£ng cao hÆ¡n
```

### Sá»­a logic tÃ¡ch data
File: `hierarchical_dataloader.py`, line ~90
```python
def process_example(example):
    text = example['text']
    
    # TODO: Thay báº±ng logic cá»§a báº¡n
    # VÃ­ dá»¥: dÃ¹ng regex, parse markdown, etc.
    question = extract_with_your_method(text)
    plan = extract_with_your_method(text)
    execution = extract_with_your_method(text)
    
    return {'question': ..., 'plan': ..., 'execution': ...}
```

## ğŸ¨ Visualize mask

```python
from models.hierarchical_mask import create_hierarchical_mask
import matplotlib.pyplot as plt

mask = create_hierarchical_mask(
    seqlen=1024, block_size=16,
    question_len=256, plan_len=256, exec_len=512
)

plt.imshow(mask.float(), cmap='RdYlGn')
plt.savefig('my_mask.png')
```

Kiá»ƒm tra:
- âœ… VÃ¹ng Plan-to-Execution pháº£i **TRáº®NG** (khÃ´ng attend)
- âœ… Execution-to-Plan pháº£i **XANH** (cÃ³ attend)

## ğŸ“Š Cáº¥u trÃºc Sequence

```
Training input:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Question â”‚ Plan_xt  â”‚ Plan_x0  â”‚ Exec_xt  â”‚ Exec_x0  â”‚
â”‚  (256)  â”‚  (256)   â”‚  (256)   â”‚  (512)   â”‚  (512)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â””â”€ Noisy â”€â”˜ â””â”€Cleanâ”€â”˜ â””â”€ Noisy â”€â”˜ â””â”€Cleanâ”€â”˜

Total length: 256 + 256*2 + 512*2 = 1792 tokens
```

## ğŸ› Debug nhanh

### Lá»—i: "Mask shape mismatch"
```python
# Check dimensions:
total = question_len + plan_len*2 + exec_len*2
print(f"Expected mask shape: {total}x{total}")
print(f"Actual mask shape: {mask.shape}")
```

### Lá»—i: "CUDA OOM"
```bash
# Trong training script:
BATCH_SIZE=16     # Giáº£m tá»« 64
MODEL_SIZE=tiny   # Thay vÃ¬ small
```

### Model khÃ´ng há»c
1. Print data samples: Check format Ä‘Ãºng chÆ°a
2. Visualize attention: Check mask Ä‘Ãºng chÆ°a
3. Reduce LR: `LR=1e-4`
4. Increase warmup: `WARMUP_STEPS=20000`

## ğŸ“ Getting Help

### CÃ¢u há»i thÆ°á»ng gáº·p:

**Q: LÃ m sao biáº¿t mask Ä‘Ãºng?**
A: Run `python test_hierarchical_mask.py` - pháº£i pass táº¥t cáº£ tests

**Q: Data cá»§a tÃ´i khÃ´ng cÃ³ format [Q, P, E]?**  
A: Sá»­a `process_example()` trong `hierarchical_dataloader.py`

**Q: Muá»‘n thá»­ vá»›i data cÃ³ sáºµn?**
A: DÃ¹ng OpenWebText, collator sáº½ tá»± split (25% Q, 25% P, 50% E)

**Q: Training bao lÃ¢u?**
A: 
- Test (1K steps): ~30 phÃºt (1 GPU)
- Small run (10K steps): ~5 giá»
- Full training (100K steps): ~48 giá»

**Q: LÃ m sao biáº¿t Ä‘ang work?**
A:
- Loss giáº£m liÃªn tá»¥c
- Valid NELBO giáº£m
- Check generated samples cÃ³ structure

## ğŸ“š Files Ä‘á»ƒ Ä‘á»c thÃªm

1. **HIERARCHICAL_README.md**: Full documentation (Vietnamese)
2. **IMPLEMENTATION_SUMMARY.md**: Chi tiáº¿t implementation
3. **models/hierarchical_mask.py**: Code + comments chi tiáº¿t
4. **test_hierarchical_mask.py**: Examples + verification

## âœ… Checklist

TrÆ°á»›c khi train:
- [ ] Test mask passed: `python test_hierarchical_mask.py`
- [ ] Visualization looks correct: Check `.png` file
- [ ] Data format verified: Print 3-5 samples
- [ ] Hyperparameters set: Check training script
- [ ] Output dir created: `mkdir outputs/test_run`

Sau 1000 steps Ä‘áº§u:
- [ ] Loss Ä‘ang giáº£m (check tensorboard/logs)
- [ ] No errors/warnings
- [ ] Generated samples cÃ³ structure (optional)

## ğŸš€ Production Checklist

Khi ready to scale:
- [ ] Data quality checked thoroughly
- [ ] Hyperparameters tuned (LR, warmup, etc.)
- [ ] Multiple seeds tested
- [ ] Evaluation metrics defined
- [ ] Comparison vá»›i baseline

---

**Báº¯t Ä‘áº§u tá»« Ä‘Ã¢y:** Run `python test_hierarchical_mask.py` âœ¨
