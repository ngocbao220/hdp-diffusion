#!/usr/bin/env python3
"""
So sÃ¡nh chi tiáº¿t BASELINE vs HDP training
"""

from transformers import AutoTokenizer
from hdp_dataset import HDPDataset
import torch

tokenizer = AutoTokenizer.from_pretrained('gpt2')
tokenizer.pad_token = tokenizer.eos_token

print("="*80)
print("âš–ï¸  SO SÃNH CHI TIáº¾T: BASELINE vs HDP")
print("="*80)

# === 1. BASELINE FORMAT ===
print("\n" + "="*80)
print("1ï¸âƒ£  BASELINE GSM8K FORMAT")
print("="*80)

import datasets
baseline_ds = datasets.load_dataset('gsm8k', 'main', split='train[:1]', cache_dir='.cache')
sample = baseline_ds[0]

baseline_text = f"Question: {sample['question']}\nAnswer: {sample['answer']}"
baseline_tokens = tokenizer(baseline_text, max_length=512, padding='max_length', 
                            truncation=True, return_tensors='pt')

print(f"\nğŸ“ Sample text:")
print(baseline_text[:300] + "...")
print(f"\nğŸ“Š Format:")
print(f"   Structure: Simple concatenation")
print(f"   Prefix: 'Question: ' and 'Answer: '")
print(f"   No special tokens")
print(f"   Token count: {(baseline_tokens['input_ids'] != tokenizer.pad_token_id).sum().item()} real tokens")
print(f"   Padding: {(baseline_tokens['input_ids'] == tokenizer.pad_token_id).sum().item()} pad tokens")

# Decode Ä‘á»ƒ xem
decoded_baseline = tokenizer.decode(baseline_tokens['input_ids'][0], skip_special_tokens=False)
print(f"\nğŸ”¤ Decoded (first 400 chars):")
print(decoded_baseline[:400])

# === 2. HDP FORMAT ===
print("\n" + "="*80)
print("2ï¸âƒ£  HDP FORMAT (Hierarchical Dual-Process)")
print("="*80)

hdp_dataset = HDPDataset(
    data_path='/workspace/hdp-diffusion/data/gsm8k/gsm8k_hierarchical_train.json',
    tokenizer=tokenizer,
    block_sizes=(128, 128, 256),
    use_special_format=True
)

hdp_sample = hdp_dataset[0]
decoded_hdp = tokenizer.decode(hdp_sample['input_ids'], skip_special_tokens=False)

print(f"\nğŸ“ Structure:")
print(f"   Block 0 (Question): 128 tokens")
print(f"   Block 1 (Plan): 128 tokens â†’ [PLAN] prefix")
print(f"   Block 2 (Execution): 256 tokens â†’ [EXECUTION] ... [ANSWER]")
print(f"   Total: 512 tokens (fixed)")

# TÃ¡ch tá»«ng block
q_block = tokenizer.decode(hdp_sample['input_ids'][:128], skip_special_tokens=False)
p_block = tokenizer.decode(hdp_sample['input_ids'][128:256], skip_special_tokens=False)
e_block = tokenizer.decode(hdp_sample['input_ids'][256:512], skip_special_tokens=False)

print(f"\nğŸ”¤ Block 0 - Question (first 150 chars):")
print(q_block[:150] + "...")

print(f"\nğŸ”¤ Block 1 - Plan (first 150 chars):")
print(p_block[:150] + "...")

print(f"\nğŸ”¤ Block 2 - Execution (first 200 chars):")
print(e_block[:200] + "...")

# Check special tokens
has_plan = '[PLAN]' in decoded_hdp
has_exec = '[EXECUTION]' in decoded_hdp or '[EXEC]' in decoded_hdp
has_answer = '[ANSWER]' in decoded_hdp

print(f"\nâœ… Special tokens:")
print(f"   [PLAN]: {'âœ“' if has_plan else 'âœ—'}")
print(f"   [EXECUTION]: {'âœ“' if has_exec else 'âœ—'}")
print(f"   [ANSWER]: {'âœ“' if has_answer else 'âœ—'}")

# === 3. KEY DIFFERENCES ===
print("\n" + "="*80)
print("3ï¸âƒ£  KEY DIFFERENCES")
print("="*80)

print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aspect              â”‚ BASELINE             â”‚ HDP                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Format              â”‚ Simple Q&A           â”‚ Hierarchical 3-block â”‚
â”‚ Special Tokens      â”‚ None                 â”‚ [PLAN][EXEC][ANSWER] â”‚
â”‚ Sequence Length     â”‚ Variable (padded)    â”‚ Fixed 512 tokens     â”‚
â”‚ Attention           â”‚ Full bidirectional   â”‚ Hierarchical mask    â”‚
â”‚ Planning            â”‚ Implicit             â”‚ Explicit [PLAN] step â”‚
â”‚ Answer Separation   â”‚ Inline with steps    â”‚ [ANSWER] token       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ ADVANTAGES OF HDP:

1. **Explicit Reasoning Structure**
   - Baseline: Question vÃ  answer trá»™n láº«n
   - HDP: TÃ¡ch biá»‡t question â†’ plan â†’ execution â†’ answer
   
2. **Hierarchical Attention**
   - Baseline: Plan vÃ  execution nhÃ¬n tháº¥y táº¥t cáº£
   - HDP: Plan KHÃ”NG nhÃ¬n tháº¥y execution (causal reasoning)
   
3. **Easier to Parse**
   - Baseline: Cáº§n parse "#### 42" Ä‘á»ƒ láº¥y answer
   - HDP: [ANSWER] token rÃµ rÃ ng

4. **Fixed Block Sizes**
   - Baseline: Variable length â†’ khÃ³ optimize
   - HDP: Fixed 128+128+256 â†’ better batching

5. **Training Signal**
   - Baseline: Model há»c cáº£ question + answer cÃ¹ng lÃºc
   - HDP: Model há»c phÃ¢n táº§ng: think (plan) â†’ solve (exec) â†’ conclude (answer)
""")

print("\n" + "="*80)
print("âœ… RECOMMENDATION")
print("="*80)
print("""
Äá»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh GSM8K tá»‘t nháº¥t:

1. **Baseline**: DÃ¹ng Ä‘á»ƒ establish performance floor
   - ÄÆ¡n giáº£n, dá»… implement
   - KhÃ´ng cÃ³ inductive bias vá» reasoning structure

2. **HDP**: DÃ¹ng Ä‘á»ƒ improve reasoning capability
   - Hierarchical structure matches human reasoning
   - Explicit planning step
   - Better interpretability

ğŸ’¡ NÃªn train cáº£ 2 Ä‘á»ƒ so sÃ¡nh performance!
""")
